# From public libraries
import streamlit as st

# from langchain_community.vectorstores import Chroma
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

from langchain.chains.retrieval import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

from logics import user_query_handler2 
from helper_functions.utility import check_password

if not check_password():  
    st.stop()

llm = ChatOpenAI(model='gpt-4o-mini')
embeddings = OpenAIEmbeddings(model='text-embedding-3-small')

# Files had to be downloaded into Gdrive as EDB website blocked by Incapsula
pdf_ids = ["1IS8YnifyuRtUnGKqfO8pSLFdXTfRZz4p", 
        "1q2qJd5bB5IlUQFQ3UD04m61TuQr_aMZI",
        "1WAp0mwlLP1L1m_K-pi4eYLAOkMXwP4qN",
        "1pdOlrAxatMG66XIFrgNS5QHDbpa2zj6S",
        "1MpMcTwc38IAiGKgPz89bpnde6AlZ2SFu",
        "1hMyce8e1w73ajycEGpt8QGLgTBsG7mXn",
        "1Kb8iJQ-8ZooRq3wFAJfCCvnP3mrL2Ask",
        "1dEZyB33mANIyCgPZBxQQeRE1YxoJa3eq",
        "1ZAIj9yFhjRAFjZWH2HsMNG_LGwOsvFAJ",
        "1SqIjmPrVttY6O3KCtjHSwDMEsG47MTtY",
        "16Itk3D_7p_06nW6tvykVVZFEFEyXUwkt",
        "1mCOIrWOtf8jWUYres9SeDJ6EjF4_gdTd",
        "15bCC4EadbyTbpMUnticaD-XhLBilDqdd",
        "1LGDX5c5BYEaJ7WGxzAGDfKD9NexcSFuf",
        ]

corpus = user_query_handler2.compile_pdfs(pdf_ids)

corpus_split = user_query_handler2.splitter(corpus)

vector_store = FAISS.from_documents(
    # collection_name = "EDB_Incentives",
    documents = corpus_split,
    embedding = embeddings,
    # persist_directory = "./edb_db"
)

st.title('''Find out how EDB's incentives and facilitation could support your business.''')

form = st.form(key="form")

user_prompt = form.text_area("Tell me more about business activities you wish to set up in Singapore:", height=150)

if form.form_submit_button("Submit"):
    # Get user input
    st.toast(f"User Input Submitted - {user_prompt}")

    prompt = ChatPromptTemplate.from_template("""
    Use the following context to answer the user's question.

    Context:
    {context}
    
    Question:
    {input}
                                              
    Instructions:
    - Answer based ONLY on the provided context
    - State which incentive or facilitation you are obtaining the response for
    - For information on incentive amounts (percentages) or criteria, provide your response in the form of an organized table. 
    - If the question asked is out of the provided context, respond with "I don't have that information"                                      
    """)

    chain = create_retrieval_chain(
        retriever=vector_store.as_retriever(k=5),
        combine_docs_chain=create_stuff_documents_chain(llm, prompt)
    )

    response = chain.invoke({"input": user_prompt})

    # Display response generated by the LLM onto the frontend 
    st.write(response["answer"])
    print(response)

    # vector_store.delete_collection()